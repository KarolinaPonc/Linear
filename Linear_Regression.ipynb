{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Linear_Regression.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGviSD0j28Dq",
        "colab_type": "text"
      },
      "source": [
        "<center>\n",
        "<h1>Linear regression introduction</h1>\n",
        "<h2>\n",
        "Deep learning classes<br>\n",
        "</h2>\n",
        "<h3>\n",
        "This is a graded assignment<br>\n",
        "</h3>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnZT1_-F28Dr",
        "colab_type": "text"
      },
      "source": [
        "### Basic information\n",
        "<ul>\n",
        "    <li>This task is build of:\n",
        "    <ul>\n",
        "        <li>Descriptions (in the Markdown cells)\n",
        "        <li>Already prepared fragments of code\n",
        "        <li>The placeholders for your code\n",
        "    </ul>\n",
        "    <li>Your code should be entered in the `Code` cells. The places are marked by <b># ENTER YOUR CODE HERE</b> note.\n",
        "    <li>Usually you should enter only a few lines of code. But if you think you need it, you may use as many lines and add as many new code cells as you wish.\n",
        "    <li>You should solve the assignment in the defined order. It is often impossible to solve the next task, if you did not sove the previous one.\n",
        "    <li>This assignment is graded. \n",
        "    <li>During the grading you may expect some questions. <b>Sending the code to the teacher is not sufficient for passing.</b>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZNFwNsU28Du",
        "colab_type": "text"
      },
      "source": [
        "Here we import all the necessary libraries, and set some initial parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS9uqjFu28Dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The line below downloads the helper from github repository. \n",
        "# Uncomment it osiem, if you are opening the notebook in Google Colab directly from the GitHub\n",
        "\n",
        "#!wget https://raw.githubusercontent.com/PrzemekSekula/DeepLearningClasses1/master/LinearRegression/helper_linear_regression.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPgyY7HC28Dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import helper_linear_regression as hlp\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWalKusp28D3",
        "colab_type": "text"
      },
      "source": [
        "The cell below is used for generating the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4LDRKmi28D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The line below assures that the random function will return the same values every time\n",
        "np.random.seed(12)\n",
        "\n",
        "coefs = [50, 25, -1.25, 0.01]\n",
        "datalength = 80\n",
        "noise = 0.2\n",
        "\n",
        "x, y = hlp.getXY(coefs, datalength, noise)\n",
        "\n",
        "f = plt.figure()\n",
        "plt.scatter(x, y)\n",
        "plt.title('Your dataset')\n",
        "plt.xlabel('X (inputs)')\n",
        "plt.ylabel('Y (labels / targets)');\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsuWlG3P28D-",
        "colab_type": "text"
      },
      "source": [
        "### Task 1\n",
        "Let's assume that your function is linear ($y = \\Theta_0 + \\Theta_1*x$). Try to select the $\\Theta_0$ i  $\\Theta_1$ manually in order to create your model. Use the code below for visualizing results.\n",
        "\n",
        "*Note: This task is not about machine learning. You should just select the parameters manually, in order to get a good intuition. The parateres should be \"quite good\", but they do not have to be perfect.* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abe9pakY28D_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "281208a6-945c-4f84-d423-c9ace65e04a1"
      },
      "source": [
        "my_th0 = 30\n",
        "my_th1 = -10\n",
        "\n",
        "hlp.plot_fitting_lin(x, y, my_th0, my_th1);"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKRcEXRj28ED",
        "colab_type": "text"
      },
      "source": [
        "### Task 2  - Hypothesis\n",
        "Prepare the function, which can compute the progosed values $h(x)$ according to the formula:\n",
        "\n",
        "<center>\n",
        "$h(x)  = \\Theta_0 + \\Theta_1 * x$\n",
        "</center>\n",
        "\n",
        "Function arguments:\n",
        "<li>x - input data (vector0\n",
        "<li>th0 - $\\Theta_0$\n",
        "<li>th1 - $\\Theta_1$\n",
        "<br \\>\n",
        "Function returns:\n",
        "<li>h - vector of values computed with the formula above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z8O33YP28ED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_h(x, th0, th1):\n",
        "    x = np.asarray(x) # It removes problems with older version of libraries\n",
        "    h = th0 + th1 * x\n",
        "    return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wss2ludi28EG",
        "colab_type": "text"
      },
      "source": [
        "#### Task 2 - test code\n",
        "You may use the code below, to test your output. The correct results are:<br>\n",
        "[200 185 170 155 140 125 110  95  80  65]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_Nx7cgK28EH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ec5493ab-f5a9-4294-e3a2-a224c27504ec"
      },
      "source": [
        "hlp.testcomputeh(compute_h)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing results:  [200 185 170 155 140 125 110  95  80  65]\n",
            "Your code seems to be OK!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXR12djH28EK",
        "colab_type": "text"
      },
      "source": [
        "### Task 3 - Cost function\n",
        "Prepare the function, which computes the cost, according to the formula:\n",
        "<br /><br />\n",
        "<center>\n",
        "$J = \\frac{1}{2m}\\sum_{i=1}^{m}{(y_i - h(x_i))}^2$\n",
        "</center>\n",
        "\n",
        "Where:\n",
        "\n",
        "<li>$J$ - cost\n",
        "<li>$y$ - real $y$ values\n",
        "<li>$y_{pred}$ - predicted $y$ values\n",
        "<li>$m$ - length of the $y$ vector (number of observations)\n",
        "\n",
        "Arguments:\n",
        "\n",
        "<li>y - vector with real y values\n",
        "<li>h - vector with predicted y values ($h(x)$)\n",
        "\n",
        "Function returns:\n",
        "\n",
        "<li> c - cost computed with the given formula.\n",
        "    \n",
        "    \n",
        "*Note: You may compute the mean value of the vector by using: np.mean() function.\n",
        "Example:*\n",
        "<code>\n",
        "X = [1, 2, 3]\n",
        "print (np.mean(X))\n",
        "2\n",
        "</code>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71ZTI-Hc28EL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost(y, ypred):\n",
        "    y = np.asarray(y) # It removes problems with older version of libraries\n",
        "    ypred = np.asarray(ypred) # It removes problems with older version of librarie\n",
        "    m = y.shape[0]\n",
        "    c = 1/(2*m) * sum([(y[i] - ypred[i])**2 for i in range(m)])\n",
        "    return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xf9Xmc028ER",
        "colab_type": "text"
      },
      "source": [
        "#### Task 4 - test code\n",
        "You may test your `cost` function with the code below. If everything is OK, the output will be:<br>\n",
        "**Your code seems to be OK!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyYCqU8c28ER",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "502b8692-1ee1-4abb-c97c-059dccdd7f2a"
      },
      "source": [
        "hlp.testcost(cost)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your code seems to be OK!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjtNVorc28EU",
        "colab_type": "text"
      },
      "source": [
        "### Task 4 - Computing cost\n",
        "Using the parameters $\\Theta_0$ i $\\Theta_1$ selected in the task 1 compute and display the hypothesis and the cost value.\n",
        "\n",
        "*Note 1: Your parameters are stored in `my_th0` and `my_th1` variables.*<br>\n",
        "*Note 1: You may use your `compute_h` function for computing hypothesis, and `cost` function for computing cost*<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gabz82T28EV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c234ff0-65f7-42f6-e95f-65152d3aba58"
      },
      "source": [
        "h = compute_h(x, my_th0, my_th1) # ENTER YOUR CODE HERE\n",
        "mycost = cost(y, h)  # ENTER YOUR CODE HERE\n",
        "print (mycost)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30062.43290276281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpwaPOGt28EX",
        "colab_type": "text"
      },
      "source": [
        "### Task 5 - partial derivatives\n",
        "Prepare the function `compute_derivatives`, which returns the partial derivatives $\\frac{\\delta}{\\delta\\Theta_0}J(\\Theta_0, \\Theta_1)$ and $\\frac{\\delta}{\\delta\\Theta_0}J(\\Theta_0, \\Theta_1)$ where:\n",
        "<center>\n",
        "<br \\><br \\>\n",
        "$J(\\Theta_0, \\Theta_1) = \\frac{1}{2m}\\sum_{i=1}^{m}{(y_i - h_\\Theta(x_i))}^2= \\frac{1}{2m}\\sum_{i=1}^{m}{(y_i - (\\Theta_0 + \\Theta_1x_i))}$\n",
        "<br \\><br \\>\n",
        "$\\frac{\\delta}{\\delta\\Theta_0}J(\\Theta_0, \\Theta_1) = - \\frac{1}{m}\\sum_{i=1}^{m}{(y_i - h_\\Theta(x_i))}$\n",
        "<br \\><br \\>\n",
        "$\\frac{\\delta}{\\delta\\Theta_1}J(\\Theta_0, \\Theta_1) = - \\frac{1}{m}\\sum_{i=1}^{m}{(y_i - h_\\Theta(x_i))x_i}$\n",
        "<br \\><br \\>\n",
        "</center>\n",
        "\n",
        "Arguments:\n",
        "<li>x - input data vector\n",
        "<li>y - output data (labels) vector\n",
        "<li>th0 - $\\Theta_0$ parameter\n",
        "<li>th1 - $\\Theta_1$ parameter\n",
        "<br \\>\n",
        "\n",
        "Function returns:\n",
        "<li>dTh0 - partial derivative $\\frac{\\delta}{\\delta\\Theta_0}J(\\Theta_0, \\Theta_1)$\n",
        "<li>dTh1 - partial derivative $\\frac{\\delta}{\\delta\\Theta_1}J(\\Theta_0, \\Theta_1)$\n",
        "<br \\><br \\>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGEvpgzW28EY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_derivatives(x, y, th0, th1):\n",
        "    x = np.asarray(x) # It removes problems with older version of libraries\n",
        "    y = np.asarray(y) # It removes problems with older version of libraries\n",
        "    m = x.shape[0]\n",
        "\n",
        "    dTh0 = 1.0/m * sum([(th0 + th1*x[i] - y[i]) for i in range(m)]) \n",
        "    dTh1 = 1.0/m * sum([(th0 + th1*x[i] - y[i])*x[i] for i in range(m)])\n",
        "    \n",
        "    return dTh0, dTh1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy4FVDo528Ec",
        "colab_type": "text"
      },
      "source": [
        "#### Task 4 - test code\n",
        "You may test your `compute_derivative` function with the code below. If everything is OK, the output will be:<br>\n",
        "**dTh0 seems to be OK.**<br>\n",
        "**dTh1 seems to be OK.**<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAbaokE528Ed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f593732d-0ddb-46a4-bfd5-22e5fd3f0b17"
      },
      "source": [
        "hlp.testcomputederivatives(compute_derivatives)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dTh0 seems to be OK.\n",
            "dTh1 seems to be OK.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjxtGHSP28Eh",
        "colab_type": "text"
      },
      "source": [
        "### Task 6 - updating theta\n",
        "Prepare the `update_theta` function, which updates the values of $\\Theta$ parameters according to the formulas:\n",
        "<center>\n",
        "<br \\><br \\>\n",
        "$\\Theta_0 = \\Theta_0 - \\alpha * \\frac{\\delta}{\\delta\\Theta_0}J(\\Theta_0, \\Theta_1)$\n",
        "<br \\><br \\>\n",
        "$\\Theta_1 = \\Theta_1 - \\alpha * \\frac{\\delta}{\\delta\\Theta_1}J(\\Theta_0, \\Theta_1)$\n",
        "<br \\><br \\>\n",
        "<br \\><br \\>\n",
        "</center>\n",
        "\n",
        "Arguments:\n",
        "<li>th0 - $\\Theta_0$ parameter\n",
        "<li>th1 - $\\Theta_1$ parameter\n",
        "<li>del0 - Partial derivative $\\frac{\\delta}{\\delta\\Theta_0}J(\\Theta_0, \\Theta_1)$\n",
        "<li>del1 - Partial derivative $\\frac{\\delta}{\\delta\\Theta_1}J(\\Theta_0, \\Theta_1)$\n",
        "<li>learning_rate - the learning rate $\\alpha$ parameter\n",
        "<br \\><br \\>\n",
        "Function returns:\n",
        "<li>Updated value of $\\Theta_0$\n",
        "<li>Updated value of $\\Theta_1$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mpTKPxY28Ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_theta(th0, th1, del0, del1, learning_rate):\n",
        "\n",
        "    # ENTER YOUR CODE HERE\n",
        "    th0 = th0 - learning_rate * del0\n",
        "    th1 = th1 - learning_rate * del1\n",
        "    \n",
        "    # END OF YOUR CODE\n",
        "    return th0, th1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mBXKw7E28El",
        "colab_type": "text"
      },
      "source": [
        "#### Task 5 - test code\n",
        "You may test your `update_theta` function with the code below. If everything is OK, the output will be:<br>\n",
        "**theta0 seems to be OK.**<br>\n",
        "**theta1 seems to be OK.**<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muJ8MjYo28El",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "079616c4-683e-476c-de52-1f078690dc22"
      },
      "source": [
        "hlp.testupdatetheta(update_theta)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "theta0 seems to be OK.\n",
            "theta1 seems to be OK.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-4_snuu28Ep",
        "colab_type": "text"
      },
      "source": [
        "### Task 7 - learning parameters\n",
        "Tune the learning parameters and run the code below. This code will perform entire machine learning, using the functions you prepared in previous tasks.<br>\n",
        "The parameters are as follows:\n",
        "<ul>\n",
        "    <li>learning_rate - $\\alpha$ - learning coefficient. The greater $\\alpha$ the larger change of $\\Theta$ values in each iteration.\n",
        "    <li>epochs - how many times we should repeat the iterations\n",
        "</ul>\n",
        "<br \\><br \\>\n",
        "Additional parameter:\n",
        "<ul>\n",
        "<li>display_every - how often should we display the $\\Theta$ and cost values. This parameter does not play any role in learning process, it is only for observations. The value <code> display_every = int(epochs / 20) </code> is reasonable, but you may change it if you wish.\n",
        "</ul>\n",
        "    \n",
        "    \n",
        "*Note: The results for this part may differ because they depend on your parameters. To pass you need to push your cost below 15000. The optimal results are:*<br>\n",
        "<li>$\\Theta_0$ = 352.40171716\n",
        "<li>$\\Theta_1$ = -17.49921637\n",
        "<li>$J(\\Theta_0, \\Theta_1)$ = 14725.144411377056\n",
        "    \n",
        "**WARNING: It is almost impossible to get the optimal parameters with this algorithm. If your cost $J(\\Theta_0, \\Theta_1)$ is below 14800 it means you did very well. If your cost is below 14730 you are perfect :)**\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ckc5cxZ28Eq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.1 # ENTER YOUR CODE HERE (Tune this parameter)\n",
        "epochs = 50 # ENTER YOUR CODE HERE (Tune this parameter)\n",
        "\n",
        "display_every = int(epochs / 20)\n",
        "\n",
        "th0 = 0 #The initial th0 value\n",
        "th1 = 0 #The initial th1 value\n",
        "\n",
        "cost_list = [] # we will use this list to plot the cost function chart\n",
        "iter_list = [] # we will use this list to plot the cost function chart\n",
        "\n",
        "for i in range(epochs):\n",
        "    #Learning process. With your functions the entire learning code is only 2 lines\n",
        "    del0, del1 = compute_derivatives(x, y, th0, th1)\n",
        "    th0, th1 = update_theta(th0, th1, del0, del1, learning_rate)\n",
        "    \n",
        "    #This code is used only for displaying results. You do not need to understand it\n",
        "    if ((i%display_every) == 0) | (i == epochs-1):\n",
        "        curr_cost = cost(y, compute_h(x, th0, th1))\n",
        "        cost_list.append(curr_cost)\n",
        "        iter_list.append(i)\n",
        "        print('Iteration {}, Theta 0: {:.2f}, Theta 1: {:.2f}, Cost: {:.2f}'\n",
        "              .format(i, th0, th1, curr_cost))\n",
        "\n",
        "        \n",
        "#This code is used only for displaying results. You do not need to understand it\n",
        "f = plt.figure()\n",
        "plt.plot(iter_list, cost_list)\n",
        "plt.title(\"Cost function\")\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Cost');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeOFRlog28Es",
        "colab_type": "text"
      },
      "source": [
        "You may use the code below to present your results on the chart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jaHCVVN28Et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\nYour results:')\n",
        "print ('h(x) = {:.2f} + x*{:.2f}'.format(th0, th1))\n",
        "print('Cost = {:.2f}'.format(cost(y, compute_h(x, th0, th1))))\n",
        "\n",
        "hlp.plot_fitting_lin(x, y, th0, th1);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEK3Pmx428E0",
        "colab_type": "text"
      },
      "source": [
        "### Question 1\n",
        "Compare the 'manual' results with the 'gradient descent' results using the code below. Which results are better:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJwcyrmm28E0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('The gradient descent results:')\n",
        "print ('h(x) = {:.2f} + x*{:.2f}'.format(th0, th1))\n",
        "print('Cost = {:.2f}'.format(cost(y, compute_h(x, th0, th1))))\n",
        "\n",
        "print('\\nThe manual results:')\n",
        "print ('h(x) = {:.2f} + x*{:.2f}'.format(my_th0, my_th1))\n",
        "print('Cost = {:.2f}'.format(cost(y, compute_h(x, my_th0, my_th1))))\n",
        "print('\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "tQP5_jRn28E2",
        "colab_type": "text"
      },
      "source": [
        "**ENTER YOUR ANSWER HERE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znHwPeZo28E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}